{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/scottchu/Projects/learning/snorkel-tutorials/recsys'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if os.path.basename(os.getcwd()) == \"snorkel-tutorials\":\n",
    "  os.chdir(\"./recsys\")\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommender System Tutorial\n",
    "A setting similar to the Netflix challenge, but with books instead of movies. Given a set of users and books, and for each user, it is given a set of books they have interacted with (read or marked as-to-read). User does not provide any numerical ratings for the books they read, except in a small number of cases. Similarly, some user have written some text reviews.\n",
    "\n",
    "The goal is to build a recommender system by training a classifier to predict whether a user will read and like any given book. The model will be trained over a user-book pair to predict a `rating` (a `rating` of 1 means the user will read and like the book). To simplify inference, user will be represented by the set of books they interacted with (rather than learning a specific representation of each user). Once the model is trained, it can be used to recommend books to a user when they visit the site. It is possible to predict the rating for the user paired with a book for a few tousand likely books, then pick the books with the top ten predicted ratings.\n",
    "\n",
    "We will use the Goodreads dataset, from \"Item Recommendation on Monotonic Behavior Chains\", and \"Fine-Grained Spoiler Detection from Large-Scale Review Corpora\". In this dataset, we have user interactions and reviews for Young Adult novels from the Goodreads website, along with metadata (like `title` and `authors`) for the novels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data and Context\n",
    "- `user_idx`: A unique identifier for a suer\n",
    "- `book_idx`: A unique identifier for a book that is being rated by the user\n",
    "- `book_idxs`: The set of books that the user has interacted with (read or planned to read)\n",
    "- `review_text`: Optional text review written by the user for the book\n",
    "- `rating`: Either `0` (means the user did not read or did not like the book) or `1` (means the user read and liked the book). The `rating` field is missing for `df_train`. The objective is to predict whether a given user (represented by the set of book_idxs the user has interacted with) will read and like any given book. that is, we want to train a model that takes a set of `book_idxs` (the user) and a single `book_idx` (the book to rate) and predicts the `rating`.\n",
    "- `df_books`: Contains books with metadata for that book (`title` and `first_author`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import download_and_process_data\n",
    "\n",
    "(df_train, df_test, df_dev, df_valid), df_books = download_and_process_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>book_id</th>\n",
       "      <th>country_code</th>\n",
       "      <th>description</th>\n",
       "      <th>is_ebook</th>\n",
       "      <th>language_code</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>similar_books</th>\n",
       "      <th>text_reviews_count</th>\n",
       "      <th>title</th>\n",
       "      <th>first_author</th>\n",
       "      <th>book_idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[293603]</td>\n",
       "      <td>4.35</td>\n",
       "      <td>10099492</td>\n",
       "      <td>US</td>\n",
       "      <td>It all comes down to this.\\nVlad's running out...</td>\n",
       "      <td>True</td>\n",
       "      <td>eng</td>\n",
       "      <td>152</td>\n",
       "      <td>[25861113, 7430195, 18765937, 6120544, 3247550...</td>\n",
       "      <td>9</td>\n",
       "      <td>Twelfth Grade Kills (The Chronicles of Vladimi...</td>\n",
       "      <td>293603</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[4018722]</td>\n",
       "      <td>3.71</td>\n",
       "      <td>22642971</td>\n",
       "      <td>US</td>\n",
       "      <td>The future world is at peace.\\nElla Shepherd h...</td>\n",
       "      <td>True</td>\n",
       "      <td>eng</td>\n",
       "      <td>1525</td>\n",
       "      <td>[20499652, 17934493, 13518102, 16210411, 17149...</td>\n",
       "      <td>428</td>\n",
       "      <td>The Body Electric</td>\n",
       "      <td>4018722</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[6537142]</td>\n",
       "      <td>3.89</td>\n",
       "      <td>31556136</td>\n",
       "      <td>US</td>\n",
       "      <td>A gorgeously written and deeply felt literary ...</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "      <td>109</td>\n",
       "      <td>[]</td>\n",
       "      <td>45</td>\n",
       "      <td>Like Water</td>\n",
       "      <td>6537142</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[6455200, 5227552]</td>\n",
       "      <td>3.90</td>\n",
       "      <td>18522274</td>\n",
       "      <td>US</td>\n",
       "      <td>Zoe Vanderveen is on the run with her captor t...</td>\n",
       "      <td>True</td>\n",
       "      <td>en-US</td>\n",
       "      <td>191</td>\n",
       "      <td>[25063023, 18553080, 17567752, 18126509, 17997...</td>\n",
       "      <td>6</td>\n",
       "      <td>Volition (The Perception Trilogy, #2)</td>\n",
       "      <td>6455200</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[187837]</td>\n",
       "      <td>3.19</td>\n",
       "      <td>17262776</td>\n",
       "      <td>US</td>\n",
       "      <td>The war is over, but for thirteen-year-old Rac...</td>\n",
       "      <td>True</td>\n",
       "      <td>eng</td>\n",
       "      <td>248</td>\n",
       "      <td>[16153997, 10836616, 17262238, 16074827, 13628...</td>\n",
       "      <td>68</td>\n",
       "      <td>Little Red Lies</td>\n",
       "      <td>187837</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               authors  average_rating   book_id country_code  \\\n",
       "3             [293603]            4.35  10099492           US   \n",
       "4            [4018722]            3.71  22642971           US   \n",
       "5            [6537142]            3.89  31556136           US   \n",
       "12  [6455200, 5227552]            3.90  18522274           US   \n",
       "13            [187837]            3.19  17262776           US   \n",
       "\n",
       "                                          description  is_ebook language_code  \\\n",
       "3   It all comes down to this.\\nVlad's running out...      True           eng   \n",
       "4   The future world is at peace.\\nElla Shepherd h...      True           eng   \n",
       "5   A gorgeously written and deeply felt literary ...      True                 \n",
       "12  Zoe Vanderveen is on the run with her captor t...      True         en-US   \n",
       "13  The war is over, but for thirteen-year-old Rac...      True           eng   \n",
       "\n",
       "    ratings_count                                      similar_books  \\\n",
       "3             152  [25861113, 7430195, 18765937, 6120544, 3247550...   \n",
       "4            1525  [20499652, 17934493, 13518102, 16210411, 17149...   \n",
       "5             109                                                 []   \n",
       "12            191  [25063023, 18553080, 17567752, 18126509, 17997...   \n",
       "13            248  [16153997, 10836616, 17262238, 16074827, 13628...   \n",
       "\n",
       "    text_reviews_count                                              title  \\\n",
       "3                    9  Twelfth Grade Kills (The Chronicles of Vladimi...   \n",
       "4                  428                                  The Body Electric   \n",
       "5                   45                                         Like Water   \n",
       "12                   6              Volition (The Perception Trilogy, #2)   \n",
       "13                  68                                    Little Red Lies   \n",
       "\n",
       "    first_author  book_idx  \n",
       "3         293603         0  \n",
       "4        4018722         1  \n",
       "5        6537142         2  \n",
       "12       6455200         3  \n",
       "13        187837         4  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_books.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_idx</th>\n",
       "      <th>book_idxs</th>\n",
       "      <th>book_idx</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>214186</th>\n",
       "      <td>8283</td>\n",
       "      <td>(9134, 25220, 17164, 17493, 1429, 29145, 23157...</td>\n",
       "      <td>25220</td>\n",
       "      <td>1</td>\n",
       "      <td>4.5*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>357653</th>\n",
       "      <td>13814</td>\n",
       "      <td>(17461, 15013, 13560, 25955, 27690, 20410, 117...</td>\n",
       "      <td>4220</td>\n",
       "      <td>1</td>\n",
       "      <td>I must say that this book will evoke different...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691372</th>\n",
       "      <td>26865</td>\n",
       "      <td>(13995, 24232, 19221, 2578, 6711, 8755, 8139, ...</td>\n",
       "      <td>30827</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29419</th>\n",
       "      <td>1169</td>\n",
       "      <td>(15660, 21161, 21162, 12921, 25965, 10394, 840...</td>\n",
       "      <td>10844</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539209</th>\n",
       "      <td>20822</td>\n",
       "      <td>(7047, 8517, 18228, 16282, 25444, 18231, 9760,...</td>\n",
       "      <td>22472</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_idx                                          book_idxs  book_idx  \\\n",
       "214186      8283  (9134, 25220, 17164, 17493, 1429, 29145, 23157...     25220   \n",
       "357653     13814  (17461, 15013, 13560, 25955, 27690, 20410, 117...      4220   \n",
       "691372     26865  (13995, 24232, 19221, 2578, 6711, 8755, 8139, ...     30827   \n",
       "29419       1169  (15660, 21161, 21162, 12921, 25965, 10394, 840...     10844   \n",
       "539209     20822  (7047, 8517, 18228, 16282, 25444, 18231, 9760,...     22472   \n",
       "\n",
       "        rating                                        review_text  \n",
       "214186       1                                               4.5*  \n",
       "357653       1  I must say that this book will evoke different...  \n",
       "691372       1                                                NaN  \n",
       "29419        0                                                NaN  \n",
       "539209       1                                                NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dev.sample(frac=1, random_state=12).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing Labeling Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "POSITIVE = 1\n",
    "NEGATIVE = 0\n",
    "ABSTAIN = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Theory: Author\n",
    "When a user interacted with several books written by an author, there is a good chance that the user will read and like other books by the same author."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling.lf import labeling_function\n",
    "\n",
    "book_to_first_author = dict(zip(df_books.book_idx, df_books.first_author))\n",
    "\n",
    "first_author_to_books_df = df_books.groupby(\"first_author\")[[\"book_idx\"]].agg(set)\n",
    "first_author_to_books = dict(\n",
    "  zip(\n",
    "    first_author_to_books_df.index,\n",
    "    first_author_to_books_df.book_idx\n",
    "  )\n",
    ")\n",
    "\n",
    "@labeling_function(\n",
    "  resources=dict(\n",
    "    book_to_first_author=book_to_first_author,\n",
    "    first_author_to_books=first_author_to_books\n",
    "  )\n",
    ")\n",
    "def shared_first_author(x, book_to_first_author, first_author_to_books):\n",
    "  author = book_to_first_author[x.book_idx]\n",
    "  same_author_books = first_author_to_books[author]\n",
    "  num_read = len(set(x.book_idxs).intersection(same_author_books))\n",
    "  return POSITIVE if num_read > 15 else ABSTAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Theory: Review\n",
    "Long text reviews written by users to guess whether they liked or disliked a book. For example, the third `df_dev` entry above has a review with the text `'4.5 STARS`, which indicates that the user liked the book. We write a simple LF that looks for similar phrases to guess the user's rating of a book. Anything 4 stars or above to indicate a positive rating, while < 4 is negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_rating_stars = [\n",
    "  \"one star\",\n",
    "  \"two star\",\n",
    "  \"three star\",\n",
    "\n",
    "  \"1 star\",\n",
    "  \"2 star\",\n",
    "  \"2.5 star\",\n",
    "  \"3 star\",\n",
    "  \"3.5 star\",\n",
    "\n",
    "  \"1 out of 5 \",\n",
    "  \"2 out of 5 \",\n",
    "  \"3 out of 5 \"\n",
    "]\n",
    "\n",
    "high_rating_stars = [\n",
    "  \"four stars\",\n",
    "  \"five stars\",\n",
    "  \"4 stars\",\n",
    "  \"4.5 stars\",\n",
    "  \"5 stars\"\n",
    "]\n",
    "\n",
    "@labeling_function(\n",
    "  resources=dict(\n",
    "    low_rating_stars=low_rating_stars,\n",
    "    high_rating_stars=high_rating_stars\n",
    "  )\n",
    ")\n",
    "def stars_in_review(x, low_rating_stars, high_rating_stars):\n",
    "  if not isinstance(x.review_text, str):\n",
    "    return ABSTAIN\n",
    "\n",
    "  review_text = x.review_text.lower()\n",
    "\n",
    "  for low_rating_star in low_rating_stars:\n",
    "    if low_rating_star in review_text:\n",
    "      return NEGATIVE\n",
    "\n",
    "  for high_rating_star in high_rating_stars:\n",
    "    if high_rating_star in review_text:\n",
    "      return POSITIVE\n",
    "\n",
    "  return ABSTAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Theory: Sentiment\n",
    "Analyze the reviews by `TextBlob` and use its polarity and subjectivity scores to estimate the user's rating for the book. These thresholds were picked by analyzing the score distributions and running error analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.preprocess import preprocessor\n",
    "from textblob import TextBlob\n",
    "\n",
    "@preprocessor(memoize=True)\n",
    "def textblob_polarity(x):\n",
    "  if isinstance(x.review_text, str):\n",
    "    x.blob = TextBlob(x.review_text)\n",
    "  else:\n",
    "    x.blob = None\n",
    "\n",
    "  return x\n",
    "\n",
    "@labeling_function(pre=[textblob_polarity])\n",
    "def polarity_positive(x):\n",
    "  return POSITIVE if x.blob and x.blob.polarity > 0.3 else ABSTAIN\n",
    "\n",
    "@labeling_function(pre=[textblob_polarity])\n",
    "def subjectivity_positive(x):\n",
    "  return POSITIVE if x.blob and x.blob.subjectivity > 0.75 else ABSTAIN\n",
    "\n",
    "@labeling_function(pre=[textblob_polarity])\n",
    "def polarity_negative(x):\n",
    "  return NEGATIVE if x.blob and x.blob.polarity < 0.0 else ABSTAIN\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7881/7881 [00:02<00:00, 2826.31it/s]\n"
     ]
    }
   ],
   "source": [
    "from snorkel.labeling import PandasLFApplier, LFAnalysis\n",
    "\n",
    "lfs = [\n",
    "  stars_in_review,\n",
    "  shared_first_author,\n",
    "  polarity_positive,\n",
    "  polarity_negative,\n",
    "  subjectivity_positive\n",
    "]\n",
    "\n",
    "applier = PandasLFApplier(lfs=lfs)\n",
    "L_dev = applier.apply(df_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "      <th>Correct</th>\n",
       "      <th>Incorrect</th>\n",
       "      <th>Emp. Acc.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>stars_in_review</th>\n",
       "      <td>0</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>0.016368</td>\n",
       "      <td>0.004822</td>\n",
       "      <td>0.001903</td>\n",
       "      <td>98</td>\n",
       "      <td>31</td>\n",
       "      <td>0.759690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shared_first_author</th>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.046948</td>\n",
       "      <td>0.000888</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>222</td>\n",
       "      <td>148</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>polarity_positive</th>\n",
       "      <td>2</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.046948</td>\n",
       "      <td>0.013323</td>\n",
       "      <td>0.000634</td>\n",
       "      <td>305</td>\n",
       "      <td>65</td>\n",
       "      <td>0.824324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>polarity_negative</th>\n",
       "      <td>3</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.017764</td>\n",
       "      <td>0.005202</td>\n",
       "      <td>0.004695</td>\n",
       "      <td>92</td>\n",
       "      <td>48</td>\n",
       "      <td>0.657143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subjectivity_positive</th>\n",
       "      <td>4</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.020810</td>\n",
       "      <td>0.015480</td>\n",
       "      <td>0.004187</td>\n",
       "      <td>117</td>\n",
       "      <td>47</td>\n",
       "      <td>0.713415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       j Polarity  Coverage  Overlaps  Conflicts  Correct  \\\n",
       "stars_in_review        0   [0, 1]  0.016368  0.004822   0.001903       98   \n",
       "shared_first_author    1      [1]  0.046948  0.000888   0.000508      222   \n",
       "polarity_positive      2      [1]  0.046948  0.013323   0.000634      305   \n",
       "polarity_negative      3      [0]  0.017764  0.005202   0.004695       92   \n",
       "subjectivity_positive  4      [1]  0.020810  0.015480   0.004187      117   \n",
       "\n",
       "                       Incorrect  Emp. Acc.  \n",
       "stars_in_review               31   0.759690  \n",
       "shared_first_author          148   0.600000  \n",
       "polarity_positive             65   0.824324  \n",
       "polarity_negative             48   0.657143  \n",
       "subjectivity_positive         47   0.713415  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LFAnalysis(L=L_dev, lfs=lfs).lf_summary(df_dev.rating.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying labeling functions to the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 797088/797088 [04:10<00:00, 3182.94it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5000/5000 [00:00<00:00, 5668.79epoch/s]\n"
     ]
    }
   ],
   "source": [
    "from snorkel.labeling.model import LabelModel\n",
    "\n",
    "L_train = applier.apply(df_train)\n",
    "label_model = LabelModel(cardinality=2, verbose=True)\n",
    "label_model.fit(L_train, n_epochs=5000, seed=123, log_freq=20, lr=0.01)\n",
    "preds_train = label_model.predict(L_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import filter_unlabeled_dataframe\n",
    "\n",
    "df_train_filtered, preds_train_filtered = filter_unlabeled_dataframe(\n",
    "  df_train, preds_train, L_train)\n",
    "\n",
    "df_train_filtered[\"rating\"] = preds_train_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rating Prediction Model\n",
    "Using a Kera model for predicting ratings given a user's book list and a book (which is being rated). The model represents the list of books the user interacted with, `books_idxs`, by learning an embedding for each idx, and averaging the embeddings in `book_idxs`. It learns another embedding for the `book_idx`, the book to be rated. Then it concatenates the two embeddings and uses an MLP to compute the probability of the `rating` being 1. this type of model is common in large-scale recommender systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from utils import precision_batch, recall_batch, f1_batch\n",
    "\n",
    "n_books = max([max(df.book_idx) for df in [df_train, df_test, df_dev, df_valid]])\n",
    "\n",
    "# Keras model to predict rating given book_idxs and book_idx\n",
    "def get_model(embed_dim=64, hidden_layer_sizes=[32]):\n",
    "  # Compute embedding for book_idxs\n",
    "  len_book_idxs = tf.keras.layers.Input([])\n",
    "  book_idxs = tf.keras.layers.Input([None])\n",
    "\n",
    "  # book_idxs % n_books is to prevent crashing if a book_idx in book_idxs is > n_books.\n",
    "  book_idxs_emb = tf.keras.layers.Embedding(n_books, embed_dim)(book_idxs % n_books)\n",
    "  book_idxs_emb = tf.math.divide(\n",
    "    tf.keras.backend.sum(book_idxs_emb, axis=1),\n",
    "    tf.expand_dims(len_book_idxs, 1)\n",
    "  )\n",
    "\n",
    "  # Compute embedding for book_idx\n",
    "  book_idx = tf.keras.layers.Input([])\n",
    "  book_idx_emb = tf.keras.layers.Embedding(n_books, embed_dim)(book_idx)\n",
    "\n",
    "  input_layer = tf.keras.layers.concatenate([book_idxs_emb, book_idx_emb], 1)\n",
    "\n",
    "  # Build Multi Layer Perceptron on input layer.\n",
    "  cur_layer = input_layer\n",
    "\n",
    "  for size in hidden_layer_sizes:\n",
    "    tf.keras.layers.Dense(size, activation=tf.nn.relu)(cur_layer)\n",
    "\n",
    "  output_layer = tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)(cur_layer)\n",
    "\n",
    "  # Create and compile keras model\n",
    "  model = tf.keras.Model(\n",
    "    inputs=[\n",
    "      len_book_idxs,\n",
    "      book_idxs,\n",
    "      book_idx\n",
    "    ],\n",
    "    outputs=[\n",
    "      output_layer\n",
    "    ]\n",
    "  )\n",
    "\n",
    "  model.compile(\n",
    "    \"Adagrad\",\n",
    "    \"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\", f1_batch, precision_batch, recall_batch]\n",
    "  )\n",
    "\n",
    "  return model\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use triples of (`book_idxs`, `book_idx`, `rating`) from our dataframes as training data points. In addition, we want to train the model to recognize when a user will not read a book. To create data points for that, we randomly sample a `bookd_id` not in `book_idxs` and use that with a `rating` of 0 as a random negative dat point for every positive (`rating` 1) data point in our dataframe so that positive and negative data points are roughly balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator to turn dataframe into data points.\n",
    "def get_data_points_generator(df):\n",
    "    def generator():\n",
    "        for book_idxs, book_idx, rating in zip(df.book_idxs, df.book_idx, df.rating):\n",
    "            # Remove book_idx from book_idxs so the model can't just look it up.\n",
    "            book_idxs = tuple(filter(lambda x: x != book_idx, book_idxs))\n",
    "            yield {\n",
    "                \"len_book_idxs\": len(book_idxs),\n",
    "                \"book_idxs\": book_idxs,\n",
    "                \"book_idx\": book_idx,\n",
    "                \"label\": rating,\n",
    "            }\n",
    "            if rating == 1:\n",
    "                # Generate a random negative book_id not in book_idxs.\n",
    "                random_negative = np.random.randint(0, n_books)\n",
    "                while random_negative in book_idxs:\n",
    "                    random_negative = np.random.randint(0, n_books)\n",
    "                yield {\n",
    "                    \"len_book_idxs\": len(book_idxs),\n",
    "                    \"book_idxs\": book_idxs,\n",
    "                    \"book_idx\": random_negative,\n",
    "                    \"label\": 0,\n",
    "                }\n",
    "\n",
    "    return generator\n",
    "\n",
    "\n",
    "def get_data_tensors(df):\n",
    "    # Use generator to get data points each epoch, along with shuffling and batching.\n",
    "    padded_shapes = {\n",
    "        \"len_book_idxs\": [],\n",
    "        \"book_idxs\": [None],\n",
    "        \"book_idx\": [],\n",
    "        \"label\": [],\n",
    "    }\n",
    "    dataset = (\n",
    "        tf.data.Dataset.from_generator(\n",
    "            get_data_points_generator(df), {k: tf.int64 for k in padded_shapes}\n",
    "        )\n",
    "        .shuffle(123)\n",
    "        .repeat(None)\n",
    "        .padded_batch(batch_size=256, padded_shapes=padded_shapes)\n",
    "    )\n",
    "    tensor_dict = tf.compat.v1.data.make_one_shot_iterator(dataset).get_next()\n",
    "    return (\n",
    "        (\n",
    "            tensor_dict[\"len_book_idxs\"],\n",
    "            tensor_dict[\"book_idxs\"],\n",
    "            tensor_dict[\"book_idx\"],\n",
    "        ),\n",
    "        tensor_dict[\"label\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "245/300 [=======================>......] - ETA: 0s - loss: 0.6953 - accuracy: 0.4531 - f1_batch: 0.3469 - precision_batch: 0.3469 - recall_batch: 0.3469WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 40 batches). You may need to use the repeat() function when building your dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 40 batches). You may need to use the repeat() function when building your dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 726us/step - loss: 0.6952 - accuracy: 0.4467 - f1_batch: 0.3200 - precision_batch: 0.3200 - recall_batch: 0.3200 - val_loss: 0.6940 - val_accuracy: 0.4414 - val_f1_batch: 0.4055 - val_precision_batch: 0.3949 - val_recall_batch: 0.4941\n",
      "Epoch 2/30\n",
      "300/300 [==============================] - 0s 411us/step - loss: 0.6926 - accuracy: 0.5333 - f1_batch: 0.1133 - precision_batch: 0.1133 - recall_batch: 0.1133  \n",
      "Epoch 3/30\n",
      "300/300 [==============================] - 0s 405us/step - loss: 0.6904 - accuracy: 0.5767 - f1_batch: 0.1100 - precision_batch: 0.1100 - recall_batch: 0.1100      \n",
      "Epoch 4/30\n",
      "300/300 [==============================] - 0s 412us/step - loss: 0.6885 - accuracy: 0.5967 - f1_batch: 0.0733 - precision_batch: 0.0733 - recall_batch: 0.0733  \n",
      "Epoch 5/30\n",
      "300/300 [==============================] - 0s 408us/step - loss: 0.6889 - accuracy: 0.5967 - f1_batch: 0.0500 - precision_batch: 0.0500 - recall_batch: 0.0500  \n",
      "Epoch 6/30\n",
      "300/300 [==============================] - 0s 407us/step - loss: 0.6881 - accuracy: 0.6033 - f1_batch: 0.0567 - precision_batch: 0.0567 - recall_batch: 0.0567  \n",
      "Epoch 7/30\n",
      "300/300 [==============================] - 0s 438us/step - loss: 0.6876 - accuracy: 0.5833 - f1_batch: 0.0433 - precision_batch: 0.0433 - recall_batch: 0.0433  \n",
      "Epoch 8/30\n",
      "300/300 [==============================] - 0s 413us/step - loss: 0.6839 - accuracy: 0.6300 - f1_batch: 0.0500 - precision_batch: 0.0500 - recall_batch: 0.0500  \n",
      "Epoch 9/30\n",
      "300/300 [==============================] - 0s 479us/step - loss: 0.6843 - accuracy: 0.6233 - f1_batch: 0.0500 - precision_batch: 0.0500 - recall_batch: 0.0500  \n",
      "Epoch 10/30\n",
      "300/300 [==============================] - 0s 460us/step - loss: 0.6822 - accuracy: 0.6100 - f1_batch: 0.0267 - precision_batch: 0.0267 - recall_batch: 0.0267  \n",
      "Epoch 11/30\n",
      "300/300 [==============================] - 0s 423us/step - loss: 0.6841 - accuracy: 0.5833 - f1_batch: 0.0367 - precision_batch: 0.0367 - recall_batch: 0.0367  \n",
      "Epoch 12/30\n",
      "300/300 [==============================] - 0s 412us/step - loss: 0.6824 - accuracy: 0.6000 - f1_batch: 0.0400 - precision_batch: 0.0400 - recall_batch: 0.0400  \n",
      "Epoch 13/30\n",
      "300/300 [==============================] - 0s 414us/step - loss: 0.6812 - accuracy: 0.6067 - f1_batch: 0.0367 - precision_batch: 0.0367 - recall_batch: 0.0367      \n",
      "Epoch 14/30\n",
      "300/300 [==============================] - 0s 410us/step - loss: 0.6796 - accuracy: 0.6000 - f1_batch: 0.0300 - precision_batch: 0.0300 - recall_batch: 0.0300  \n",
      "Epoch 15/30\n",
      "300/300 [==============================] - 0s 411us/step - loss: 0.6796 - accuracy: 0.6167 - f1_batch: 0.0467 - precision_batch: 0.0467 - recall_batch: 0.0467  \n",
      "Epoch 16/30\n",
      "300/300 [==============================] - 0s 456us/step - loss: 0.6827 - accuracy: 0.5700 - f1_batch: 0.0367 - precision_batch: 0.0367 - recall_batch: 0.0367      \n",
      "Epoch 17/30\n",
      "300/300 [==============================] - 0s 406us/step - loss: 0.6764 - accuracy: 0.6300 - f1_batch: 0.0400 - precision_batch: 0.0400 - recall_batch: 0.0400\n",
      "Epoch 18/30\n",
      "300/300 [==============================] - 0s 412us/step - loss: 0.6790 - accuracy: 0.5867 - f1_batch: 0.0400 - precision_batch: 0.0400 - recall_batch: 0.0400      \n",
      "Epoch 19/30\n",
      "300/300 [==============================] - 0s 407us/step - loss: 0.6752 - accuracy: 0.6233 - f1_batch: 0.0433 - precision_batch: 0.0433 - recall_batch: 0.0433      \n",
      "Epoch 20/30\n",
      "300/300 [==============================] - 0s 409us/step - loss: 0.6769 - accuracy: 0.6133 - f1_batch: 0.0433 - precision_batch: 0.0433 - recall_batch: 0.0433      \n",
      "Epoch 21/30\n",
      "300/300 [==============================] - 0s 410us/step - loss: 0.6741 - accuracy: 0.6133 - f1_batch: 0.0433 - precision_batch: 0.0433 - recall_batch: 0.0433      \n",
      "Epoch 22/30\n",
      "300/300 [==============================] - 0s 411us/step - loss: 0.6782 - accuracy: 0.6067 - f1_batch: 0.0433 - precision_batch: 0.0433 - recall_batch: 0.0433      \n",
      "Epoch 23/30\n",
      "300/300 [==============================] - 0s 405us/step - loss: 0.6716 - accuracy: 0.6333 - f1_batch: 0.0467 - precision_batch: 0.0467 - recall_batch: 0.0467  \n",
      "Epoch 24/30\n",
      "300/300 [==============================] - 0s 406us/step - loss: 0.6753 - accuracy: 0.6067 - f1_batch: 0.0467 - precision_batch: 0.0467 - recall_batch: 0.0467      \n",
      "Epoch 25/30\n",
      "300/300 [==============================] - 0s 401us/step - loss: 0.6734 - accuracy: 0.6067 - f1_batch: 0.0400 - precision_batch: 0.0400 - recall_batch: 0.0400\n",
      "Epoch 26/30\n",
      "130/300 [============>.................] - ETA: 0s - loss: 0.6711 - accuracy: 0.6462 - f1_batch: 0.0846 - precision_batch: 0.0846 - recall_batch: 0.0846            WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 9000 batches). You may need to use the repeat() function when building your dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 9000 batches). You may need to use the repeat() function when building your dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 0s 305us/step - loss: 0.6720 - accuracy: 0.6278 - f1_batch: 0.0611 - precision_batch: 0.0611 - recall_batch: 0.0611\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x463368be0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import get_n_epochs\n",
    "\n",
    "model = get_model()\n",
    "\n",
    "X_train, Y_train = get_data_tensors(df_train_filtered)\n",
    "X_valid, Y_valid = get_data_tensors(df_valid)\n",
    "model.fit(\n",
    "    X_train,\n",
    "    Y_train,\n",
    "    steps_per_epoch=300,\n",
    "    validation_data=(X_valid, Y_valid),\n",
    "    validation_steps=40,\n",
    "    epochs=get_n_epochs(),\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/30 [>.............................] - ETA: 1s - loss: 0.6728 - accuracy: 0.6667 - f1_batch: 0.0000e+00 - precision_batch: 0.0000e+00 - recall_batch: 0.0000e+00WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 30 batches). You may need to use the repeat() function when building your dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 30 batches). You may need to use the repeat() function when building your dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 0s 1ms/step - loss: 0.6869 - accuracy: 0.5977 - f1_batch: 0.2141 - precision_batch: 0.4167 - recall_batch: 0.1618        \n"
     ]
    }
   ],
   "source": [
    "X_test, Y_test = get_data_tensors(df_test)\n",
    "\n",
    "_ = model.evaluate(X_test, Y_test, steps=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Readings\n",
    "- [Netflix Prize data](https://www.kaggle.com/netflix-inc/netflix-prize-data)\n",
    "- [Recommender system](https://en.wikipedia.org/wiki/Recommender_system)\n",
    "- [Multilayer Perceptron (MLP)](https://en.wikipedia.org/wiki/Multilayer_perceptron)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
